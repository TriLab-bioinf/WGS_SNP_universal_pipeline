## Hennighausen_TK_185

### BEFORE RUNNING

1) Start an interactive session in Biowulf
```
sinteractive
```

2) Edit the config.txt file 

3) Edit the input_1.txt (for read-1 files) and input_2.txt (for read-2 files) files so they point to the fastq sequencing files to be processed, one sample per row.


### To run the pipeline automaticaly
```
run_RNASEQ_SNV_workflow.sh
```

### To run the pipeline manually, one step at a time:

Set CONFIG_FILE variable to the name of the name of the config file
```
CONFIG_FILE=config.txt
``` 

#### 1) FASTQC
```
swarm --logdir ./00-swarm-log --job-name step1-fastqc  -f ./scripts/RNASEQ_SNV-pipeline-step1-fastqc.swarm
```

#### 2) TRIMMING and MAPPING
```
swarm --logdir ./00-swarm-log --job-name step2-mapping -f ./scripts/RNASEQ_SNV-pipeline-step2-mapping.swarm
```

#### 3) SPLIT CHR
```
swarm --logdir ./00-swarm-log --job-name step3-split -f ./scripts/RNASEQ_SNV-pipeline-step3-split.swarm
```

#### 4) DELETE DISCORDANT READS
```
swarm --logdir ./00-swarm-log --job-name step4-cleanBAM -f ./scripts/RNASEQ_SNV-pipeline-step4-cleanBAM.swarm
```

#### 5) MARK DUPLICATES
```
swarm --logdir ./00-swarm-log --job-name step5-MarkDuplicates -f ./scripts/RNASEQ_SNV-pipeline-step5-MarkDuplicates.swarm
```

#### 6) BASE RECALIBRATION
```
swarm --logdir ./00-swarm-log --job-name step6-recalibration -f ./scripts/RNASEQ_SNV-pipeline-step6-recalibration.swarm
```

#### 7) SPLIT RECALIBRATED BAM FILES
```
swarm --logdir ./00-swarm-log --job-name step7-split -f ./scripts/RNASEQ_SNV-pipeline-step7-split.swarm
```

#### 8) VARIANT CALLING
```
swarm --logdir ./00-swarm-log --job-name step8-VariantCalling -f ./scripts/RNASEQ_SNV-pipeline-step8-VariantCalling.swarm
```

#### 9) Merge GTF files
```
swarm --logdir ./00-swarm-log --job-name step9-filterVariants -f ./scripts/RNASEQ_SNV-pipeline-step9-filterVariants.swarm
```


### IF YOU WANT TO CHANGE THE RUNTIME
```
type: newwall --jobid JOBID --time HH:MM:SS
```

### IF YOU WANT TO CANCEL YOUR JOB
```
scancel JOBID
```

### To clean the working directory and remove all log and result folders generated by the pipeline in the current directory:
```
clean_workflow_directory.sh
```

